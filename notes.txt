# Netflix Data Analysis Project - Complete Documentation

## ðŸ“‹ Table of Contents
1. [Project Overview](#project-overview)
2. [Technical Architecture](#technical-architecture)
3. [Setup & Installation](#setup--installation)
4. [Core Code Explanation](#core-code-explanation)
5. [Data Analysis Methods](#data-analysis-methods)
6. [Visualization Techniques](#visualization-techniques)
7. [Advanced Features](#advanced-features)
8. [Troubleshooting Guide](#troubleshooting-guide)
9. [Project Extensions](#project-extensions)
10. [Learning Outcomes](#learning-outcomes)

---

## ðŸŽ¬ Project Overview

### What This Project Does
This Python project analyzes your Netflix viewing history to uncover patterns and insights about your streaming habits. It processes raw Netflix export data and generates:
- **Statistical summaries** of your viewing behavior
- **Visual charts** showing patterns over time
- **Personalized insights** about your preferences
- **Binge-watching analysis** to identify marathon sessions

### Key Features
- ðŸ“Š **Data Cleaning & Preprocessing** - Handles real-world messy data
- ðŸ“ˆ **Multiple Visualization Types** - Bar charts, line graphs, pie charts
- ðŸ•’ **Temporal Analysis** - Daily, weekly, monthly patterns
- ðŸ¿ **Content Analysis** - Movies vs TV shows, genre preferences
- âš¡ **Binge Detection** - Identifies marathon viewing sessions

### Real-World Applications
- Personal entertainment analytics
- Digital wellness and screen time awareness
- Content recommendation research
- Portfolio project for data science roles

---

## ðŸ— Technical Architecture

### System Requirements
- **Python 3.8+** (essential for pandas compatibility)
- **4GB RAM** minimum (for data processing)
- **100MB free space** (for libraries and outputs)

### Technology Stack
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Data    â”‚ â†’  â”‚  Python Backend  â”‚ â†’  â”‚  Output Results  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                  â”‚
â”‚ â€¢ CSV Files     â”‚    â”‚ â€¢ Pandas         â”‚    â”‚ â€¢ PNG Charts     â”‚
â”‚ â€¢ Netflix Exportâ”‚    â”‚ â€¢ Matplotlib     â”‚    â”‚ â€¢ CSV Reports    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Seaborn        â”‚    â”‚ â€¢ Console Text   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure
```
netflix-analysis/
â”‚
â”œâ”€â”€ netflix_analyzer.py          # Main script
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ NetflixViewingHistory.csv    # Your data (after export)
â”œâ”€â”€ sample_data.csv             # Test data
â”œâ”€â”€ netflix_analysis.png        # Generated chart
â”œâ”€â”€ viewing_patterns.csv        # Generated report
â””â”€â”€ top_titles.csv             # Generated report
```

---

## âš™ï¸ Setup & Installation

### Step 1: Environment Setup
```bash
# Create project directory
mkdir netflix-analysis
cd netflix-analysis

# Verify Python installation
python --version
# Should show Python 3.8 or higher

# Create virtual environment (recommended)
python -m venv netflix_env
# On Windows:
netflix_env\Scripts\activate
# On Mac/Linux:
source netflix_env/bin/activate
```

### Step 2: Dependency Installation
```bash
# Method 1: Individual packages
pip install pandas matplotlib seaborn jupyter

# Method 2: Using requirements file
# Create requirements.txt with:
echo "pandas==2.0.3
matplotlib==3.7.2
seaborn==0.12.2
jupyter==1.0.0" > requirements.txt

pip install -r requirements.txt
```

### Step 3: Data Acquisition
1. **Official Method:**
   - Go to Netflix.com â†’ Account â†’ "Get your personal information"
   - Request "Viewing Activity"
   - Download when ready (24-48 hours)
   - Extract ZIP and locate `NetflixViewingHistory.csv`

2. **Sample Data (for testing):**
   ```python
   # Create sample_data.csv for testing
   import pandas as pd
   sample_data = {
       'Title': [
           "The Office: Season 2: The Dundies",
           "Stranger Things: Chapter One", 
           "Avengers: Endgame (2019)",
           "The Queen's Gambit: Openings",
           "Breaking Bad: Pilot"
       ],
       'Date': [
           '2023-10-15', '2023-10-15', '2023-10-14', 
           '2023-10-13', '2023-10-12'
       ]
   }
   pd.DataFrame(sample_data).to_csv('sample_data.csv', index=False)
   ```

---

## ðŸ’» Core Code Explanation

### 1. Data Loading Module
```python
def load_data():
    """
    Robust data loader that handles multiple file formats
    and provides helpful error messages
    """
    possible_files = [
        'NetflixViewingHistory.csv',
        'netflix-viewing-history.csv', 
        'sample_data.csv'
    ]
    
    for file in possible_files:
        if os.path.exists(file):
            df = pd.read_csv(file)
            print(f"âœ… Successfully loaded {file}")
            return df
    
    # Fallback: create sample data
    print("âš ï¸  No data file found. Creating sample data...")
    return create_sample_data()
```

**Key Concepts:**
- **Error Handling**: Graceful fallback for missing files
- **File Detection**: Multiple filename attempts
- **User Feedback**: Clear status messages

### 2. Data Cleaning Pipeline
```python
def clean_data(df):
    """
    Transforms raw Netflix data into analysis-ready format
    """
    # Standardize column names
    column_mapping = {
        'Title': 'title', 'Date': 'date', 
        'Profile Name': 'profile_name'
    }
    
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns:
            df.rename(columns={old_col: new_col}, inplace=True)
    
    # Convert and extract datetime features
    df['date'] = pd.to_datetime(df['date'])
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day_of_week'] = df['date'].dt.day_name()
    df['hour'] = df['date'].dt.hour
    
    # Content classification
    df['is_movie'] = df['title'].str.contains(r'\(\d{4}\)', na=False)
    df['is_tv_show'] = ~df['is_movie']
    
    return df
```

**Key Concepts:**
- **Data Type Conversion**: String dates â†’ DateTime objects
- **Feature Engineering**: Creating new columns from existing data
- **Boolean Indexing**: TV show vs movie classification

---

## ðŸ“Š Data Analysis Methods

### 1. Basic Statistics
```python
def show_basic_stats(df):
    """Comprehensive viewing statistics"""
    stats = {
        'total_views': len(df),
        'date_range': f"{df['date'].min().date()} to {df['date'].max().date()}",
        'active_days': df['date'].dt.date.nunique(),
        'views_per_day': len(df) / df['date'].dt.date.nunique(),
        'movie_count': df['is_movie'].sum(),
        'tv_count': df['is_tv_show'].sum()
    }
    
    # Calculate percentages
    stats['movie_percent'] = (stats['movie_count'] / stats['total_views']) * 100
    stats['tv_percent'] = (stats['tv_count'] / stats['total_views']) * 100
    
    return stats
```

### 2. Temporal Analysis
```python
def analyze_temporal_patterns(df):
    """Analyze when you watch Netflix"""
    patterns = {}
    
    # Daily patterns
    patterns['daily'] = df['day_of_week'].value_counts()
    
    # Hourly patterns  
    patterns['hourly'] = df['hour'].value_counts().sort_index()
    
    # Monthly trends
    patterns['monthly'] = df.groupby(df['date'].dt.month).size()
    
    return patterns
```

### 3. Content Analysis
```python
def analyze_content(df, top_n=10):
    """Analyze what you watch"""
    content_insights = {}
    
    # Most watched titles
    content_insights['top_titles'] = df['title'].value_counts().head(top_n)
    
    # Content type distribution
    content_insights['content_types'] = {
        'movies': df['is_movie'].sum(),
        'tv_shows': df['is_tv_show'].sum()
    }
    
    # Binge analysis
    content_insights['binge_sessions'] = find_binge_sessions(df)
    
    return content_insights
```

---

## ðŸ“ˆ Visualization Techniques

### 1. Multi-Panel Dashboard
```python
def create_dashboard(df):
    """Create a comprehensive visualization dashboard"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Netflix Viewing Analysis Dashboard', fontsize=16, fontweight='bold')
    
    # Plot 1: Top Titles (Horizontal Bar)
    top_titles = df['title'].value_counts().head(8)
    axes[0,0].barh(range(len(top_titles)), top_titles.values)
    axes[0,0].set_title('Most Watched Titles')
    
    # Plot 2: Daily Patterns (Bar Chart)
    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    day_counts = df['day_of_week'].value_counts().reindex(day_order)
    axes[0,1].bar(day_order, day_counts.values, color='skyblue')
    axes[0,1].set_title('Viewing by Day of Week')
    axes[0,1].tick_params(axis='x', rotation=45)
    
    # Plot 3: Hourly Patterns (Bar Chart)
    hour_counts = df['hour'].value_counts().sort_index()
    axes[1,0].bar(hour_counts.index, hour_counts.values, color='lightcoral')
    axes[1,0].set_title('Viewing by Hour of Day')
    
    # Plot 4: Content Types (Pie Chart)
    content_counts = [df['is_tv_show'].sum(), df['is_movie'].sum()]
    axes[1,1].pie(content_counts, labels=['TV Shows', 'Movies'], autopct='%1.1f%%')
    axes[1,1].set_title('Movies vs TV Shows')
    
    plt.tight_layout()
    return fig
```

### 2. Time Series Analysis
```python
def plot_viewing_timeline(df):
    """Show viewing activity over time"""
    # Monthly aggregation
    monthly_views = df.groupby(df['date'].dt.to_period('M')).size()
    
    plt.figure(figsize=(12, 6))
    plt.plot(monthly_views.index.astype(str), monthly_views.values, 
             marker='o', linewidth=2, markersize=6)
    plt.title('Monthly Viewing Activity Over Time')
    plt.xlabel('Month')
    plt.ylabel('Number of Views')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    
    return plt.gcf()
```

---

## ðŸ” Advanced Features

### 1. Binge-Watching Detection
```python
def find_binge_sessions(df, threshold_hours=6):
    """
    Identify binge sessions: multiple views within threshold hours
    
    Parameters:
    - df: cleaned DataFrame
    - threshold_hours: max time between views to count as same session
    """
    df_sorted = df.sort_values('date').copy()
    
    # Calculate time difference between consecutive views
    df_sorted['time_diff'] = df_sorted['date'].diff()
    
    # New session starts when time gap > threshold
    df_sorted['new_session'] = df_sorted['time_diff'] > pd.Timedelta(hours=threshold_hours)
    df_sorted['session_id'] = df_sorted['new_session'].cumsum()
    
    # Analyze sessions
    session_stats = df_sorted.groupby('session_id').agg({
        'title': 'count',
        'date': ['min', 'max']
    })
    session_stats.columns = ['views_count', 'session_start', 'session_end']
    
    # Calculate session duration
    session_stats['duration_hours'] = (
        session_stats['session_end'] - session_stats['session_start']
    ).dt.total_seconds() / 3600
    
    # Filter binge sessions (more than 1 view)
    binge_sessions = session_stats[session_stats['views_count'] > 1]
    
    return binge_sessions
```

### 2. Genre Analysis
```python
def analyze_genres(df):
    """Simple genre classification based on title keywords"""
    genre_keywords = {
        'Comedy': ['office', 'friends', 'comedy', 'stand-up', 'parks and rec'],
        'Drama': ['breaking bad', 'crown', 'the wire', 'ozark', 'better call saul'],
        'Sci-Fi/Fantasy': ['stranger things', 'dark', 'black mirror', 'witcher', 'mandalorian'],
        'Action': ['avengers', 'marvel', 'action', 'fast and furious', 'john wick'],
        'Documentary': ['documentary', 'explained', 'our planet', 'tiger king'],
        'Reality TV': ['baking show', 'love is blind', 'too hot to handle', 'circle']
    }
    
    df['detected_genre'] = 'Other'
    
    for genre, keywords in genre_keywords.items():
        for keyword in keywords:
            mask = df['title'].str.lower().str.contains(keyword, na=False)
            df.loc[mask, 'detected_genre'] = genre
    
    genre_summary = df['detected_genre'].value_counts()
    return genre_summary
```

---

## ðŸ›  Troubleshooting Guide

### Common Issues and Solutions

#### 1. File Not Found Error
```python
# Problem: CSV file not located
# Solution: Enhanced file detection
def robust_file_loading():
    possible_locations = [
        './NetflixViewingHistory.csv',
        './netflix-viewing-history.csv',
        '../NetflixViewingHistory.csv',  # Parent directory
        os.path.expanduser('~/Downloads/NetflixViewingHistory.csv')
    ]
    
    for file_path in possible_locations:
        if os.path.exists(file_path):
            return pd.read_csv(file_path)
    
    raise FileNotFoundError("Netflix data file not found in common locations")
```

#### 2. Date Parsing Errors
```python
# Problem: Various date formats in Netflix exports
# Solution: Flexible date parsing
def parse_netflix_dates(date_series):
    """Handle multiple date formats from Netflix"""
    formats_to_try = [
        '%Y-%m-%d',        # 2023-10-15
        '%d/%m/%Y',        # 15/10/2023
        '%m/%d/%Y',        # 10/15/2023
        '%Y-%m-%d %H:%M:%S' # 2023-10-15 20:30:00
    ]
    
    for fmt in formats_to_try:
        try:
            return pd.to_datetime(date_series, format=fmt)
        except ValueError:
            continue
    
    # Final fallback
    return pd.to_datetime(date_series, errors='coerce')
```

#### 3. Memory Issues with Large Datasets
```python
# Problem: Large Netflix history files
# Solution: Chunked processing
def process_large_netflix_file(file_path, chunk_size=10000):
    """Process large Netflix files in chunks"""
    chunks = []
    
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        # Clean each chunk
        cleaned_chunk = clean_data(chunk)
        chunks.append(cleaned_chunk)
    
    # Combine results
    return pd.concat(chunks, ignore_index=True)
```

---

## ðŸš€ Project Extensions

### 1. Web Dashboard with Streamlit
```python
# Create app.py for Streamlit dashboard
import streamlit as st
import pandas as pd
import plotly.express as px

def create_streamlit_app():
    st.title("ðŸŽ¬ Netflix Viewing Analytics")
    
    uploaded_file = st.file_uploader("Upload Netflix CSV", type="csv")
    
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        df = clean_data(df)
        
        # Interactive charts
        fig = px.bar(df['day_of_week'].value_counts(), 
                     title="Viewing by Day of Week")
        st.plotly_chart(fig)
        
        # Metrics
        col1, col2, col3 = st.columns(3)
        col1.metric("Total Views", len(df))
        col2.metric("Active Days", df['date'].dt.date.nunique())
        col3.metric("Favorite Day", df['day_of_week'].mode()[0])

# Run with: streamlit run app.py
```

### 2. Automated Reporting
```python
def generate_pdf_report(df, filename="netflix_report.pdf"):
    """Generate a PDF report with analysis results"""
    from matplotlib.backends.backend_pdf import PdfPages
    
    with PdfPages(filename) as pdf:
        # Title page
        plt.figure(figsize=(8, 10))
        plt.text(0.5, 0.5, "Netflix Viewing Report", 
                ha='center', va='center', size=20)
        pdf.savefig()
        plt.close()
        
        # Analysis pages
        fig = create_dashboard(df)
        pdf.savefig(fig)
        plt.close()
        
    print(f"âœ… PDF report saved as {filename}")
```

### 3. Comparative Analysis
```python
def compare_periods(df, period1, period2):
    """Compare viewing habits between two time periods"""
    mask1 = (df['date'] >= period1[0]) & (df['date'] <= period1[1])
    mask2 = (df['date'] >= period2[0]) & (df['date'] <= period2[1])
    
    period1_data = df[mask1]
    period2_data = df[mask2]
    
    comparison = {
        'period1': calculate_stats(period1_data),
        'period2': calculate_stats(period2_data),
        'change': {}
    }
    
    # Calculate percentage changes
    for key in comparison['period1']:
        if isinstance(comparison['period1'][key], (int, float)):
            change = ((comparison['period2'][key] - comparison['period1'][key]) 
                     / comparison['period1'][key]) * 100
            comparison['change'][key] = change
    
    return comparison
```

---

## ðŸŽ¯ Learning Outcomes

### Technical Skills Developed
1. **Python Programming**
   - Data structures (DataFrames, Series)
   - Function design and modular programming
   - Error handling and validation

2. **Data Analysis**
   - Data cleaning and preprocessing
   - Exploratory Data Analysis (EDA)
   - Statistical summary generation
   - Time series analysis

3. **Data Visualization**
   - Matplotlib for static charts
   - Seaborn for enhanced styling
   - Multi-panel figure creation
   - Chart customization and labeling

4. **Real-World Problem Solving**
   - Handling messy real-world data
   - Creating robust, user-friendly tools
   - Iterative development and testing

### Data Science Concepts Mastered
- **Feature Engineering**: Creating new variables from existing data
- **Temporal Analysis**: Understanding patterns over time
- **Pattern Recognition**: Identifying trends and anomalies
- **Data Wrangling**: Transforming raw data into analysis-ready format

### Next Steps for Learning
1. **Advanced Visualizations**: Learn Plotly for interactive charts
2. **Machine Learning**: Add recommendation features
3. **Web Development**: Create a Flask/Streamlit web app
4. **Database Integration**: Store results in SQLite or PostgreSQL
5. **API Development**: Create REST APIs for the analysis engine

---

## ðŸ“ Summary

This Netflix Data Analysis Project provides comprehensive experience with real-world data processing and analysis. You'll learn to:

- âœ… Work with personal data exports
- âœ… Clean and preprocess real datasets  
- âœ… Perform exploratory data analysis
- âœ… Create multiple visualization types
- âœ… Generate actionable insights
- âœ… Build a complete data analysis pipeline

The project scales from beginner to advanced levels, making it perfect for learning and portfolio development. Start with the basic analysis, then gradually implement the advanced features as your skills grow!

# Jupyter Notebook Guide for Netflix Data Analysis (Deep Dive)

## ðŸŽ¯ What is Jupyter Notebook?

### Definition
Jupyter Notebook is an **interactive computing environment** that allows you to create and share documents containing:
- **Live code**
- **Visualizations** 
- **Explanatory text**
- **Equations**

Think of it as a digital laboratory notebook for data science!

### Why Recommended for Beginners?
1. **Immediate Feedback** - See results after each step
2. **No Complex Setup** - Run code in small, manageable pieces
3. **Visual Learning** - Mix code, explanations, and charts together
4. **Error Isolation** - If one cell fails, others still work
5. **Exploration Friendly** - Perfect for data analysis and experimentation

---

## ðŸš€ Complete Jupyter Notebook Setup

### Step 1: Installation Methods

#### Method A: Using Anaconda (Easiest for Beginners)
```bash
# Download from https://www.anaconda.com/download
# Install Anaconda, then launch Jupyter:
jupyter notebook
```

#### Method B: Using pip (If Python is already installed)
```bash
# Install Jupyter
pip install jupyter

# Launch Jupyter
jupyter notebook
```

#### Method C: Using VS Code (Modern Approach)
1. Install VS Code
2. Install Python extension
3. Install Jupyter extension
4. Create `.ipynb` files and run directly in VS Code

### Step 2: Launch Jupyter Notebook
```bash
# Navigate to your project folder
cd netflix-analysis

# Start Jupyter
jupyter notebook
```

**What happens next:**
- A web browser opens automatically
- You see a file browser interface
- Your terminal shows the server logs
- **Don't close the terminal!** It's running the notebook server

---

## ðŸ““ Creating Your Netflix Analysis Notebook

### Step 3: Create New Notebook
1. Click **New** â†’ **Python 3 (ipykernel)**
2. A new tab opens with your notebook
3. Rename it: Click "Untitled" and type "Netflix Analysis"

### Step 4: Understand Notebook Structure
A notebook consists of **cells**. Each cell can be:

| Cell Type | Purpose | Keyboard Shortcut |
|-----------|---------|-------------------|
| **Code** | Write and execute Python code | `Y` |
| **Markdown** | Write explanations, headers, lists | `M` |
| **Raw** | Advanced content (rarely used) | `R` |

---

## ðŸ”¬ Step-by-Step Notebook Creation

### Cell 1: Title and Introduction (Markdown)
```markdown
# ðŸŽ¬ Netflix Viewing Analysis
## Personal Data Exploration Project

**Project Goals:**
- Analyze my Netflix viewing habits
- Discover patterns in when and what I watch
- Create visualizations of my streaming behavior
- Learn data analysis with Python

*Note: This notebook walks through the analysis step by step.*
```

**How to use:**
1. Change cell type to **Markdown**
2. Paste the text above
3. Press `Shift + Enter` to render

### Cell 2: Import Libraries (Code)
```python
# Cell 2: Import Required Libraries
print("ðŸš€ Starting Netflix Analysis...")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
from datetime import datetime

print("âœ… All libraries imported successfully!")
print(f"Pandas version: {pd.__version__}")
print(f"Matplotlib version: {plt.__version__}")

# Set up visualization style
plt.style.use('default')
sns.set_style("whitegrid")
%matplotlib inline

print("ðŸ“Š Visualization settings configured!")
```

**What happens:**
- `%matplotlib inline` makes charts appear below cells
- You'll see the print outputs immediately
- If there are errors, they appear in red below the cell

### Cell 3: Data Loading Function (Code)
```python
# Cell 3: Load Netflix Data
def load_netflix_data():
    """
    Smart function to find and load Netflix data
    Tries multiple file locations and names
    """
    print("ðŸ“ Searching for Netflix data file...")
    
    possible_files = [
        'NetflixViewingHistory.csv',
        'netflix-viewing-history.csv',
        'sample_data.csv',
        'viewing-history.csv'
    ]
    
    for filename in possible_files:
        if os.path.exists(filename):
            print(f"âœ… Found: {filename}")
            df = pd.read_csv(filename)
            print(f"ðŸ“Š Loaded {len(df)} viewing records")
            return df
    
    # If no file found, create sample data
    print("âš ï¸  No Netflix file found. Creating sample data...")
    sample_data = {
        'Title': [
            "The Office: Season 2: The Dundies",
            "Stranger Things: Chapter One: The Vanishing of Will Byers",
            "Avengers: Endgame (2019)",
            "The Queen's Gambit: Openings",
            "Breaking Bad: Pilot",
            "The Office: Season 2: Sexual Harassment",
            "Stranger Things: Chapter Two: The Weirdo on Maple Street",
            "Dark: Secrets (2017)"
        ],
        'Date': [
            '2023-10-15', '2023-10-15', '2023-10-14', '2023-10-13',
            '2023-10-12', '2023-10-11', '2023-10-10', '2023-10-09'
        ]
    }
    df = pd.DataFrame(sample_data)
    df.to_csv('sample_data.csv', index=False)
    print("âœ… Sample data created: sample_data.csv")
    return df

# Load the data
netflix_df = load_netflix_data()
```

### Cell 4: Initial Data Exploration (Code)
```python
# Cell 4: Explore the Raw Data
print("ðŸ” Initial Data Exploration")
print("=" * 50)

print("DataFrame Info:")
print(netflix_df.info())

print("\nFirst 5 rows:")
display(netflix_df.head())

print("\nColumn names:")
print(netflix_df.columns.tolist())

print("\nBasic statistics:")
print(f"Shape: {netflix_df.shape}")
print(f"Date range: {netflix_df['Date'].min()} to {netflix_df['Date'].max()}")
```

**Key Features Used:**
- `display()`: Better formatting for DataFrames in notebooks
- `.head()`: Show first few rows
- `.info()`: Data types and memory usage
- `.shape`: Dimensions of the DataFrame

### Cell 5: Data Cleaning (Markdown + Code)
```markdown
## ðŸ§¹ Data Cleaning and Preparation

In this step, we'll:
- Standardize column names
- Convert dates to proper format
- Extract useful time features
- Classify content types
```

```python
# Cell 5: Data Cleaning Process
print("Starting data cleaning...")

# Create a clean copy
df_clean = netflix_df.copy()

# Standardize column names
df_clean.rename(columns={
    'Title': 'title',
    'Date': 'date'
}, inplace=True)

# Convert to datetime
df_clean['date'] = pd.to_datetime(df_clean['date'])
print("âœ… Dates converted to datetime")

# Extract time features
df_clean['year'] = df_clean['date'].dt.year
df_clean['month'] = df_clean['date'].dt.month
df_clean['month_name'] = df_clean['date'].dt.month_name()
df_clean['day_of_week'] = df_clean['date'].dt.day_name()
df_clean['hour'] = df_clean['date'].dt.hour
print("âœ… Time features extracted")

# Classify content types
df_clean['is_movie'] = df_clean['title'].str.contains(r'\(\d{4}\)', na=False)
df_clean['is_tv_show'] = ~df_clean['is_movie']
print("âœ… Content types classified")

print("\nCleaned Data Overview:")
display(df_clean.head())
print(f"\nFinal shape: {df_clean.shape}")
```

### Cell 6: Basic Analysis (Code)
```python
# Cell 6: Basic Statistical Analysis
print("ðŸ“ˆ Basic Viewing Statistics")
print("=" * 40)

# Calculate key metrics
total_views = len(df_clean)
date_range = f"{df_clean['date'].min().strftime('%Y-%m-%d')} to {df_clean['date'].max().strftime('%Y-%m-%d')}"
active_days = df_clean['date'].dt.date.nunique()
avg_views_per_day = total_views / active_days

movies_count = df_clean['is_movie'].sum()
tv_count = df_clean['is_tv_show'].sum()

print(f"Total viewing sessions: {total_views}")
print(f"Date range: {date_range}")
print(f"Active days: {active_days}")
print(f"Average views per day: {avg_views_per_day:.2f}")
print(f"Movies watched: {movies_count} ({movies_count/total_views*100:.1f}%)")
print(f"TV episodes: {tv_count} ({tv_count/total_views*100:.1f}%)")

# Most watched titles
print("\nðŸ† Top 5 Most Watched Titles:")
top_titles = df_clean['title'].value_counts().head(5)
for title, count in top_titles.items():
    print(f"  â€¢ {title}: {count} views")
```

### Cell 7: First Visualization (Markdown + Code)
```markdown
## ðŸ“Š Creating Our First Visualization

Let's start with a simple bar chart showing our most watched titles.
This demonstrates the immediate feedback of Jupyter Notebooks!
```

```python
# Cell 7: Most Watched Titles Chart
print("Creating Most Watched Titles chart...")

plt.figure(figsize=(10, 6))
top_5_titles = df_clean['title'].value_counts().head(5)

# Create horizontal bar chart
bars = plt.barh(range(len(top_5_titles)), top_5_titles.values)
plt.yticks(range(len(top_5_titles)), top_5_titles.index)
plt.xlabel('Number of Views')
plt.title('My Most Watched Netflix Titles')
plt.gca().invert_yaxis()  # Highest on top

# Add value labels on bars
for i, bar in enumerate(bars):
    width = bar.get_width()
    plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, 
             f'{int(width)}', ha='left', va='center')

plt.tight_layout()
plt.show()

print("âœ… Chart created successfully!")
```

---

## ðŸŽ¨ Advanced Visualizations in Notebook

### Cell 8: Multi-Panel Dashboard
```python
# Cell 8: Create Analysis Dashboard
print("Creating comprehensive dashboard...")

# Create 2x2 grid of subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Netflix Viewing Analysis Dashboard', fontsize=16, fontweight='bold')

# Plot 1: Most watched titles (top-left)
top_titles = df_clean['title'].value_counts().head(6)
axes[0,0].barh(range(len(top_titles)), top_titles.values, color='skyblue')
axes[0,0].set_yticks(range(len(top_titles)))
axes[0,0].set_yticklabels([title[:25] + '...' if len(title) > 25 else title 
                          for title in top_titles.index])
axes[0,0].set_title('Most Watched Titles')
axes[0,0].set_xlabel('View Count')

# Plot 2: Viewing by day of week (top-right)
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
day_counts = df_clean['day_of_week'].value_counts().reindex(day_order)
axes[0,1].bar(day_order, day_counts.values, color='lightgreen', alpha=0.7)
axes[0,1].set_title('Viewing by Day of Week')
axes[0,1].set_xlabel('Day')
axes[0,1].set_ylabel('View Count')
axes[0,1].tick_params(axis='x', rotation=45)

# Plot 3: Viewing by hour (bottom-left)
hour_counts = df_clean['hour'].value_counts().sort_index()
axes[1,0].bar(hour_counts.index, hour_counts.values, color='salmon', alpha=0.7)
axes[1,0].set_title('Viewing by Hour of Day')
axes[1,0].set_xlabel('Hour (24h format)')
axes[1,0].set_ylabel('View Count')

# Plot 4: Content type pie chart (bottom-right)
content_types = ['TV Shows', 'Movies']
content_counts = [df_clean['is_tv_show'].sum(), df_clean['is_movie'].sum()]
axes[1,1].pie(content_counts, labels=content_types, autopct='%1.1f%%', 
              startangle=90, colors=['lightblue', 'lightcoral'])
axes[1,1].set_title('Movies vs TV Shows')

plt.tight_layout()
plt.show()

print("âœ… Dashboard created!")
```

### Cell 9: Interactive Exploration
```python
# Cell 9: Interactive Data Exploration
print("ðŸ” Interactive Exploration")
print("=" * 40)

# Let's explore different aspects of the data
print("Available analysis options:")
print("1. View specific date range")
print("2. Analyze by content type")
print("3. Find binge sessions")

# Example: Analyze last 7 days
recent_days = 7
cutoff_date = df_clean['date'].max() - pd.Timedelta(days=recent_days)
recent_views = df_clean[df_clean['date'] > cutoff_date]

print(f"\nRecent Activity (Last {recent_days} days):")
print(f"Views: {len(recent_views)}")
print(f"Different titles: {recent_views['title'].nunique()}")
print(f"Most watched recently: {recent_views['title'].value_counts().head(3).to_dict()}")

# Quick summary by day of recent activity
print(f"\nRecent daily pattern:")
recent_daily = recent_views['day_of_week'].value_counts()
display(recent_daily)
```

---

## ðŸ’¡ Jupyter Notebook Power Features

### Cell 10: Magic Commands and Tips
```python
# Cell 10: Jupyter Power Features
print("ðŸŽ© Jupyter Magic Commands and Tips")

# Timing code execution
print("Timing code execution:")
%timeit df_clean['title'].value_counts().head(5)

# Measuring memory usage
print("\nDataFrame memory usage:")
df_clean.info(memory_usage='deep')

# Display multiple outputs in one cell
from IPython.display import display, HTML

display("ðŸ“… Date Range Analysis:")
display(f"Earliest view: {df_clean['date'].min()}")
display(f"Latest view: {df_clean['date'].max()}")
display(f"Total span: {df_clean['date'].max() - df_clean['date'].min()}")

# Create a nice summary table
summary_data = {
    'Metric': ['Total Views', 'Active Days', 'Movies', 'TV Shows', 'Unique Titles'],
    'Value': [
        len(df_clean),
        df_clean['date'].dt.date.nunique(),
        df_clean['is_movie'].sum(),
        df_clean['is_tv_show'].sum(),
        df_clean['title'].nunique()
    ]
}
summary_df = pd.DataFrame(summary_data)
display("ðŸ“Š Summary Statistics:")
display(summary_df)
```

### Cell 11: Debugging and Error Handling
```python
# Cell 11: Debugging in Jupyter
print("ðŸ› Debugging and Error Handling")

# Safe function with error handling
def safe_analysis(df, analysis_type):
    try:
        if analysis_type == 'hourly':
            return df['hour'].value_counts().sort_index()
        elif analysis_type == 'daily':
            return df['day_of_week'].value_counts()
        else:
            raise ValueError(f"Unknown analysis type: {analysis_type}")
    except Exception as e:
        print(f"âŒ Error in analysis: {e}")
        return None

# Test the function
print("Testing hourly analysis:")
hourly_data = safe_analysis(df_clean, 'hourly')
if hourly_data is not None:
    display(hourly_data.head())

print("\nTesting invalid analysis (should show error):")
invalid_data = safe_analysis(df_clean, 'invalid_type')
```

---

## ðŸ’¾ Saving and Exporting Results

### Cell 12: Save Your Work
```python
# Cell 12: Export Results and Save Work
print("ðŸ’¾ Saving Results...")

# Save cleaned data
df_clean.to_csv('cleaned_netflix_data.csv', index=False)
print("âœ… Cleaned data saved: cleaned_netflix_data.csv")

# Save visualizations
plt.figure(figsize=(10, 6))
df_clean['day_of_week'].value_counts().plot(kind='bar', color='lightblue')
plt.title('Viewing by Day of Week')
plt.ylabel('Number of Views')
plt.tight_layout()
plt.savefig('netflix_weekly_pattern.png', dpi=300, bbox_inches='tight')
print("âœ… Chart saved: netflix_weekly_pattern.png")

# Save analysis summary
summary = {
    'total_views': len(df_clean),
    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'date_range': f"{df_clean['date'].min().date()} to {df_clean['date'].max().date()}",
    'most_watched_title': df_clean['title'].value_counts().index[0],
    'most_watched_count': df_clean['title'].value_counts().iloc[0]
}

import json
with open('analysis_summary.json', 'w') as f:
    json.dump(summary, f, indent=2)
print("âœ… Analysis summary saved: analysis_summary.json")

print("\nðŸŽ‰ All results saved successfully!")
```

### Cell 13: Final Summary and Next Steps
```markdown
## ðŸŽ¯ What We've Accomplished

### âœ… Skills Learned:
1. **Jupyter Notebook Basics**
   - Creating and running code cells
   - Using Markdown for documentation
   - Interactive data exploration

2. **Data Analysis Workflow**
   - Data loading and inspection
   - Data cleaning and preprocessing
   - Feature engineering
   - Statistical analysis

3. **Visualization**
   - Bar charts, pie charts, multi-panel plots
   - Customizing appearance and labels
   - Saving charts as image files

4. **Real-World Problem Solving**
   - Handling actual Netflix export data
   - Creating meaningful insights
   - Error handling and validation

### ðŸš€ Next Steps:
1. **Get your real Netflix data** and rerun this analysis
2. **Add more advanced analyses** like binge detection
3. **Create interactive visualizations** with Plotly
4. **Build a web dashboard** with Streamlit
5. **Share your notebook** with friends

### ðŸ“ Files Created:
- `cleaned_netflix_data.csv` - Processed dataset
- `netflix_weekly_pattern.png` - Visualization
- `analysis_summary.json` - Analysis results
- Your Jupyter notebook (autosaved)
```

---

## ðŸŽª Jupyter Notebook Pro Tips

### Essential Keyboard Shortcuts
| Shortcut | Action |
|----------|--------|
| `Shift + Enter` | Run cell and move to next |
| `Ctrl + Enter` | Run cell and stay |
| `Alt + Enter` | Run cell and insert new below |
| `Esc` then `A` | Insert cell above |
| `Esc` then `B` | Insert cell below |
| `Esc` then `M` | Change to Markdown |
| `Esc` then `Y` | Change to Code |
| `Esc` then `D` then `D` | Delete cell |

### Notebook Management
```python
# Useful commands for notebook management
# In a code cell, you can run:

# List all variables in memory
%who

# Show variable details
%whos

# Restart kernel and clear output
# Kernel -> Restart & Clear Output

# Run all cells above
# Cell -> Run All Above

# Export notebook as PDF/HTML
# File -> Download as
```

### Debugging Workflow
1. **Test small pieces** - One operation per cell initially
2. **Use `print()` statements** liberally for debugging
3. **Check intermediate results** with `display()`
4. **Restart kernel** if things get messy
5. **Use `%debug` magic** for post-mortem debugging

---

## ðŸŽ‰ Why Jupyter Wins for Beginners

### Immediate Gratification
- See results after every step
- No waiting for entire script to run
- Instant feedback on what works

### Learn by Experimentation
```python
# Try different things easily:
# What if we look at only movies?
movies_only = df_clean[df_clean['is_movie'] == True]
display(movies_only['title'].value_counts().head(3))

# What about weekend vs weekday?
df_clean['is_weekend'] = df_clean['day_of_week'].isin(['Saturday', 'Sunday'])
weekend_ratio = df_clean['is_weekend'].mean()
print(f"Weekend viewing ratio: {weekend_ratio:.1%}")
```

### Perfect for Data Exploration
- Mix code, charts, and explanations
- Keep a record of your thought process
- Easy to go back and modify previous steps
- Natural progression from question to answer

This deep dive into Jupyter Notebooks shows why they're the ideal starting point for data science beginners! The interactive, visual nature makes learning Python and data analysis much more engaging and effective.